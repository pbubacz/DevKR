{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME='data/html/sample-html.html'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HTML Parsing\n",
    "In this notebook we compare a few popular strategies for turning raw HTML into structured chunks you can feed into downstream pipelines.\n",
    "1. **BeautifulSoup** – a lightweight parser ideal for quick inspection or simple extraction.\n",
    "2. **Unstructured.io** – a partitioning library that automatically segments documents into typed elements.\n",
    "3. Other libraries and frameworks for HTML document parsing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeautifulSoup\n",
    "\n",
    "**Beautiful Soup** is a Python library designed for quick-turnaround web scraping and screen-scraping projects. Since 2004, it has helped developers extract data from poorly structured HTML and XML documents with minimal code. Key features include:\n",
    "\n",
    "*   **Simple navigation and search methods** for parsing and modifying document trees\n",
    "*   **Automatic encoding handling**, converting input to Unicode and output to UTF-8\n",
    "*   **Parser flexibility**, working with `lxml`, `html5lib`, and Python’s built-in parser\n",
    "*   **Powerful querying**, like finding links by class, matching URLs, or extracting nested elements\n",
    "\n",
    "Beautiful Soup is lightweight, easy to integrate, and widely used in both personal and enterprise projects. It’s available via PyPI (`pip install beautifulsoup4`) and supported on Python 3.7+. Licensed under MIT, it’s ideal for developers needing fast, reliable data extraction from messy web pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Parse the HTML file and surface common elements\n",
    "with open(FILE_NAME, 'r', encoding='utf-8') as f:\n",
    "    soup = BeautifulSoup(f, 'html.parser')\n",
    "\n",
    "title = soup.title.get_text(strip=True) if soup.title else 'N/A'\n",
    "print(f'Document title: {title}\\n')\n",
    "\n",
    "headings = [(tag.name.upper(), tag.get_text(' ', strip=True)) for tag in soup.find_all(['h1', 'h2', 'h3'])]\n",
    "if headings:\n",
    "    print('Headings:')\n",
    "    for level, text in headings:\n",
    "        print(f' - {level}: {text}')\n",
    "else:\n",
    "    print('No headings found.')\n",
    "\n",
    "links = [\n",
    "    (link.get_text(' ', strip=True) or '(no text)', link['href'])\n",
    "    for link in soup.find_all('a', href=True)\n",
    "    if not link['href'].startswith('#')\n",
    " ]\n",
    "print(f\"\\nFound {len(links)} link(s):\")\n",
    "for idx, (text, href) in enumerate(links, start=1):\n",
    "    print(f' {idx}. {text} -> {href}')\n",
    "\n",
    "paragraphs = [p.get_text(' ', strip=True) for p in soup.find_all('p')]\n",
    "if paragraphs:\n",
    "    print(f\"\\nFirst paragraph snippet: {paragraphs[0][:120]}...\")\n",
    "\n",
    "table = soup.find('table')\n",
    "if table:\n",
    "    rows = [\n",
    "        [cell.get_text(' ', strip=True) for cell in row.find_all(['th', 'td'])]\n",
    "        for row in table.find_all('tr')\n",
    "    ]\n",
    "    print('\\nFirst table preview:')\n",
    "    for row in rows[:3]:\n",
    "        print(' | '.join(row))\n",
    "else:\n",
    "    print('\\nNo table detected.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unstrunctured.io\n",
    "\n",
    "**Unstructured.io** is an open-source ETL library designed to convert complex documents—like PDFs, Word files, HTML, and images—into clean, structured data optimized for use with large language models (LLMs). It provides modular components for:\n",
    "\n",
    "*   **Document ingestion and pre-processing**\n",
    "*   **Auto-partitioning and format detection**\n",
    "*   **Table and image enrichment**\n",
    "*   **Chunking and embedding generation**\n",
    "\n",
    "Unstructured supports both local development and containerized deployment via Docker. It integrates easily with Python and offers connectors for platforms like Discord. The library is ideal for building scalable, production-grade data pipelines and is available via PyPI and GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from unstructured.partition.html import partition_html\n",
    "elements = partition_html(filename=FILE_NAME, infer_table_structure=True)\n",
    "print(f\"Parsed {len(elements)} element(s) from the HTML document.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from textwrap import shorten\n",
    "\n",
    "type_counts = Counter(element.category for element in elements)\n",
    "print('Element counts by category:')\n",
    "for category, count in type_counts.most_common():\n",
    "    print(f' - {category}: {count}')\n",
    "\n",
    "print('\\nSample elements:')\n",
    "for i, element in enumerate(elements[:5], start=1):\n",
    "    if element.category == 'Table':\n",
    "        chunk_text = element.metadata.text_as_html or ''\n",
    "    else:\n",
    "        chunk_text = element.text or ''\n",
    "    snippet = shorten(chunk_text, width=100, placeholder='…')\n",
    "    page_number = getattr(element.metadata, 'page_number', None)\n",
    "    source = getattr(element.metadata, 'filename', None)\n",
    "    metadata_bits = [f'page {page_number}' if page_number else None, source]\n",
    "    metadata_str = ' | '.join(bit for bit in metadata_bits if bit) or 'no metadata'\n",
    "    print(f\"{i}. [{element.category}] {snippet}\")\n",
    "    print(f\"    metadata: {metadata_str}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
