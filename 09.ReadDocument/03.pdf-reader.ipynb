{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF Parsing\n",
    "This notebook walks through practical ways to transform raw PDF files into structured text that downstream pipelines can consume.\n",
    "1. **PyPDF2** – lightweight local extraction for quickly reading text from each page.\n",
    "2. **Azure Document Intelligence** – cloud OCR + layout service that returns markdown with tables, figures, and structure preserved.\n",
    "3. **Utility helpers** – shared helpers for cleaning text, counting tokens, chunk inspection, and saving intermediate outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install logging tiktoken azure-ai-documentintelligence azure-core azure-identity PyPDF2 python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME = \"data/pdf/sample-pdf.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import re\n",
    "from io import BytesIO\n",
    "from typing import Iterable\n",
    "\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "from PyPDF2 import PdfReader\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "from azure.ai.documentintelligence.models import AnalyzeResult\n",
    "\n",
    "load_dotenv()\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "if not logging.getLogger().handlers:\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "        handlers=[\n",
    "            logging.FileHandler(\"debug.log\"),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def handle_pdf_locally(uploaded_file: BytesIO, clean: bool = False) -> str:\n",
    "    \"\"\"Extract text from a PDF using PyPDF2.\"\"\"\n",
    "    logger.info(\"Processing document locally\")\n",
    "    try:\n",
    "        uploaded_file.seek(0)\n",
    "        pdf_reader = PdfReader(uploaded_file)\n",
    "        texts = [(page.extract_text() or \"\") for page in pdf_reader.pages]\n",
    "        output = \"\\n\".join(texts)\n",
    "        return clean_text(output) if clean else output\n",
    "    except Exception:\n",
    "        logger.exception(\"Error processing document locally\")\n",
    "        raise\n",
    "\n",
    "def handle_pdf_remotely(uploaded_file: BytesIO, clean: bool = False) -> str:\n",
    "    \"\"\"Extract text from a PDF using Azure Document Intelligence.\"\"\"\n",
    "    logger.info(\"Processing PDF document remotely\")\n",
    "    doc_intelligence_endpoint = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT\")\n",
    "    doc_intelligence_key = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_ADMIN_KEY\")\n",
    "\n",
    "    if not doc_intelligence_endpoint or not doc_intelligence_key:\n",
    "        raise EnvironmentError(\"Azure Document Intelligence configuration is missing.\")\n",
    "\n",
    "    document_intelligence_client = DocumentIntelligenceClient(\n",
    "        endpoint=doc_intelligence_endpoint,\n",
    "        credential=AzureKeyCredential(doc_intelligence_key)\n",
    "    )\n",
    "    try:\n",
    "        uploaded_file.seek(0)\n",
    "        poller = document_intelligence_client.begin_analyze_document(\n",
    "            \"prebuilt-layout\",\n",
    "            body=uploaded_file,\n",
    "            content_type=\"application/octet-stream\",\n",
    "            output_content_format=\"markdown\"\n",
    "        )\n",
    "        result: AnalyzeResult = poller.result()\n",
    "        return clean_text(result.content) if clean else result.content\n",
    "    except Exception:\n",
    "        logger.exception(\"Error processing PDF document remotely\")\n",
    "        raise\n",
    "\n",
    "def read_file_bin(file_name: str) -> BytesIO:\n",
    "    \"\"\"Read a file from disk and return its binary contents.\"\"\"\n",
    "    logger.info(\"Reading file %s\", file_name)\n",
    "    try:\n",
    "        with open(file_name, \"rb\") as file:\n",
    "            return BytesIO(file.read())\n",
    "    except FileNotFoundError:\n",
    "        logger.exception(\"The file %s does not exist\", file_name)\n",
    "        raise\n",
    "\n",
    "def save_file(file_name: str, data: str) -> None:\n",
    "    \"\"\"Write text data to disk using UTF-8 encoding.\"\"\"\n",
    "    logger.info(\"Saving file %s\", file_name)\n",
    "    with open(file_name, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(data)\n",
    "\n",
    "def num_tokens_from_string(text: str) -> int:\n",
    "    \"\"\"Calculate token length using the configured tokenizer.\"\"\"\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "def print_chunks_page_content(page_content: Iterable) -> None:\n",
    "    \"\"\"Print basic statistics and content for each chunk.\"\"\"\n",
    "    chunks = list(page_content)\n",
    "    print(f\"Number of chunks: {len(chunks)}\")\n",
    "    for index, chunk in enumerate(chunks, start=1):\n",
    "        body = getattr(chunk, \"page_content\", str(chunk))\n",
    "        print(\n",
    "            f\"Chunk {index} character count: {len(body)} token number: {num_tokens_from_string(body)}\"\n",
    "        )\n",
    "        print(body)\n",
    "        print()\n",
    "\n",
    "def clean_text(\n",
    "    text: str,\n",
    "    remove_comments: bool = False,\n",
    "    put_html_tables_on_new_line: bool = True,\n",
    ") -> str:\n",
    "    \"\"\"Remove redundant whitespace and optionally strip HTML comments.\"\"\"\n",
    "    logger.info(\"Cleaning text\")\n",
    "    text = re.sub(\n",
    "        '(?<=<table>)(.*?)(?=</table>)',\n",
    "        lambda match: match.group(0).replace('\\n', ' '),\n",
    "        text,\n",
    "        flags=re.DOTALL,\n",
    "    )\n",
    "    patterns = {\n",
    "        '\\n+': '\\n',\n",
    "        ' +': ' ',\n",
    "        r'\\s<': '<',\n",
    "        r'>\\s': '>',\n",
    "        r'\\s\\.': '.',\n",
    "        r'\\s,': ',',\n",
    "        r'\\s!': '!',\n",
    "        r'\\s\\?': '?',\n",
    "        r'\\s:': ':',\n",
    "        r'\\s;': ';',\n",
    "        r'\\s\\)': ')',\n",
    "        r'\\(\\s': '(',\n",
    "        r'\\[\\s': '[',\n",
    "        r'\\s\\]': ']',\n",
    "        r'\\s\\}': '}',\n",
    "        r'\\}\\s': '}',\n",
    "    }\n",
    "    for pattern, replacement in patterns.items():\n",
    "        text = re.sub(pattern, replacement, text)\n",
    "    if put_html_tables_on_new_line:\n",
    "        text = text.replace('<table>', '\\n<table>')\n",
    "    if remove_comments:\n",
    "        text = re.sub(r'<!--(.*?)-->', '', text, flags=re.DOTALL)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proces document in DI and by PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=read_file_bin(FILE_NAME)\n",
    "md_file=handle_pdf_remotely(file)\n",
    "txt_file=handle_pdf_locally(file)\n",
    "\n",
    "save_file(FILE_NAME.replace(\".pdf\",\".md\"),md_file)\n",
    "save_file(FILE_NAME.replace(\".pdf\",\".txt\"),txt_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
