{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a82d1f0",
   "metadata": {},
   "source": [
    "# Azure OpenAI reasoning models\n",
    "\n",
    "Azure OpenAI reasoning models are designed to tackle reasoning and problem-solving tasks with increased focus and capability. These models spend more time processing and understanding the user's request, making them exceptionally strong in areas like science, coding, and math compared to previous iterations.\n",
    "\n",
    "Key capabilities of reasoning models:\n",
    "\n",
    "- Complex Code Generation: Capable of generating algorithms and handling advanced coding tasks to support developers.\n",
    "- Advanced Problem Solving: Ideal for comprehensive brainstorming sessions and addressing multifaceted challenges.\n",
    "- Complex Document Comparison: Perfect for analyzing contracts, case files, or legal documents to identify subtle differences.\n",
    "- Instruction Following and Workflow Management: Particularly effective for managing workflows requiring shorter contexts.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746ebfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "url = f\"{os.getenv('AZURE_OPENAI_ENDPOINT')}openai/v1\"\n",
    "key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "model = os.getenv(\"AZURE_OPENAI_COMPLETION_MODEL\")\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=key,\n",
    "    base_url=url\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-5-mini\", # replace with the model deployment name of your o1 deployment.\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"What steps should I think about when writing my first Python API?\"},\n",
    "    ],\n",
    "    max_completion_tokens = 5000\n",
    "\n",
    ")\n",
    "\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4461c08a",
   "metadata": {},
   "source": [
    "# Reasoning effort\n",
    "Reasoning models have reasoning_tokens as part of completion_tokens_details in the model response. These are hidden tokens that aren't returned as part of the message response content but are used by the model to help generate a final answer to your request. reasoning_effort can be set to low, medium, or high for all reasoning models except o1-mini. GPT-5 reasoning models support a new reasoning_effort setting of minimal. The higher the effort setting, the longer the model will spend processing the request, which will generally result in a larger number of reasoning_tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3eecfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-5-mini\", \n",
    "    messages=[\n",
    "        {\"role\": \"developer\",\"content\": \"You are a helpful assistant.\"}, \n",
    "        {\"role\": \"user\", \"content\": \"What steps should I think about when writing my first Python API?\"},\n",
    "    ],\n",
    "    max_completion_tokens = 5000,\n",
    "    reasoning_effort = \"medium\" # low, medium, or high\n",
    ")\n",
    "\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f208ad3",
   "metadata": {},
   "source": [
    "# Reasoning summary\n",
    "When using the latest reasoning models with the Responses API you can use the reasoning summary parameter to receive summaries of the model's chain of thought reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4faa886",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.responses.create(\n",
    "    input=\"Tell me about the curious case of neural text degeneration\",\n",
    "    model=\"gpt-5\", # replace with model deployment name\n",
    "    reasoning={\n",
    "        \"effort\": \"medium\",\n",
    "        \"summary\": \"auto\" # auto, concise, or detailed, gpt-5 series do not support concise \n",
    "    },\n",
    "    text={\n",
    "        \"verbosity\": \"low\" # New with GPT-5 models\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response.model_dump_json(indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
